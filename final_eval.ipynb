{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfsXWWngQv8TQ75vjssCp6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install python-Levenshtein"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LORWUik4PKD","executionInfo":{"status":"ok","timestamp":1764559908708,"user_tz":300,"elapsed":19866,"user":{"displayName":"Compute DeepLearning","userId":"08902558907758790473"}},"outputId":"f03b3bf5-b5d5-4592-f476-1300371cd0b5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.3)\n","Requirement already satisfied: Levenshtein==0.27.3 in /usr/local/lib/python3.12/dist-packages (from python-Levenshtein) (0.27.3)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein==0.27.3->python-Levenshtein) (3.14.3)\n"]}]},{"cell_type":"code","source":["import csv\n","from google.colab import userdata\n","from io import BytesIO\n","import json\n","import os\n","import numpy as np\n","import pandas as pd\n","import re\n","import requests\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.datasets import make_regression\n","import Levenshtein\n","import regex as re\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2IyiFi3R4Rqz","executionInfo":{"status":"ok","timestamp":1764559909550,"user_tz":300,"elapsed":817,"user":{"displayName":"Compute DeepLearning","userId":"08902558907758790473"}},"outputId":"7ad5a46c-ce90-4eab-9b09-3ff4cc701112"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json\n","import re\n","import Levenshtein\n","from sklearn.metrics import f1_score, mean_absolute_error\n","\n","\n","# -------------------------------------------------------------------------\n","# PARSE TRUTH FIELD FROM THE CSV\n","# -------------------------------------------------------------------------\n","def parse_truth_field(text):\n","    \"\"\"\n","    Parse truth rows such as:\n","      max: 78.0, min: 12.0, range: 0.0-90.0,\n","      title: ..., domain: healthcare\n","    \"\"\"\n","\n","    result = {\n","        \"maximum\": None,\n","        \"minimum\": None,\n","        \"range\": None,\n","        \"title\": None,\n","        \"domain\": None\n","    }\n","\n","    if not isinstance(text, str):\n","        return result\n","\n","    # Extract max, min, range\n","    m_max   = re.search(r\"max:\\s*([0-9.]+)\", text, flags=re.I)\n","    m_min   = re.search(r\"min:\\s*([0-9.]+)\", text, flags=re.I)\n","    m_range = re.search(r\"range:\\s*([0-9.]+-[0-9.]+)\", text, flags=re.I)\n","\n","    if m_max:   result[\"maximum\"] = m_max.group(1)\n","    if m_min:   result[\"minimum\"] = m_min.group(1)\n","    if m_range: result[\"range\"]   = m_range.group(1)\n","\n","    # Full title between \"title:\" and \", domain:\"\n","    m_title = re.search(r\"title:\\s*(.*?)(?=,\\s*domain:|$)\", text, flags=re.I)\n","    if m_title:\n","        result[\"title\"] = m_title.group(1).strip()\n","\n","    # Domain\n","    m_domain = re.search(r\"domain:\\s*([A-Za-z]+)\", text, flags=re.I)\n","    if m_domain:\n","        result[\"domain\"] = m_domain.group(1).strip().lower()  # truth may be normalized\n","\n","    return result\n","\n","# -------------------------------------------------------------------------\n","# PARSE PRED FIELD FROM THE CSV\n","# -------------------------------------------------------------------------\n","def parse_pred_field(text):\n","    \"\"\"\n","    Parse pred rows such as:\n","    {\n","      \"maximum\": 77.0,\n","      \"minimum\": 12.0,\n","      \"range\": \"12-77\",\n","      \"title\": \"...\",\n","      \"domain\": \"healthcare\"\n","    }\n","\n","    Pred values MUST NOT be modified.\n","    \"\"\"\n","\n","    result = {\n","        \"maximum\": None,\n","        \"minimum\": None,\n","        \"range\": None,\n","        \"title\": None,\n","        \"domain\": None\n","    }\n","\n","    if not isinstance(text, str):\n","        return result\n","\n","    try:\n","        # Convert JSON string → Python dict\n","        data = json.loads(text)\n","    except Exception:\n","        return result\n","\n","    # Copy fields if present (DO NOT modify)\n","    for key in [\"maximum\", \"minimum\", \"range\", \"title\", \"domain\"]:\n","        if key in data:\n","            result[key] = data[key]\n","\n","    return result\n","\n","\n","# -------------------------------------------------------------------------\n","# RANGE PARSER — TRUTH DATA MAY BE CLEANED, PRED DATA IS NEVER MODIFIED\n","# -------------------------------------------------------------------------\n","def extract_bounds(series, fix_truth=False):\n","    \"\"\"\n","    Convert strings like '0-100', '9.2-9.45', '\"12-77\"', \"'200-500'\"\n","    into lower, upper float values.\n","\n","    fix_truth = True → allow repairs (swap reversed, remove bad characters)\n","    fix_truth = False → pred must remain unchanged except parsing.\n","    \"\"\"\n","\n","    lowers, uppers = [], []\n","\n","    for raw in series:\n","        s = str(raw).strip()\n","\n","        # Remove wrapping quotes ONLY for parsing (not modifying values)\n","        s_clean = s.replace('\"', '').replace(\"'\", \"\").strip()\n","        s_clean = s_clean.replace(\" \", \"\")\n","\n","        m = re.match(r\"^([0-9.]+)-([0-9.]+)$\", s_clean)\n","        if not m:\n","            lowers.append(np.nan)\n","            uppers.append(np.nan)\n","            continue\n","\n","        low, high = float(m.group(1)), float(m.group(2))\n","\n","        if fix_truth:\n","            # Only adjust truth data\n","            if low > high:\n","                low, high = high, low\n","\n","        lowers.append(low)\n","        uppers.append(high)\n","\n","    return np.array(lowers), np.array(uppers)\n","\n","\n","# -------------------------------------------------------------------------\n","# MAIN EVALUATION FUNCTION\n","# -------------------------------------------------------------------------\n","def evaluate(csv_path, save_path, model_name=\"model\"):\n","\n","    df = pd.read_csv(csv_path)\n","\n","    # ------------------------------------------------------------\n","    # PARSE TRUTH + PRED\n","    # ------------------------------------------------------------\n","    truth_dicts = df[\"truth\"].apply(parse_truth_field)\n","    pred_dicts  = df[\"pred\"].apply(parse_pred_field)   # never modified\n","\n","    # Expand fields\n","    for key in [\"maximum\", \"minimum\", \"range\", \"title\", \"domain\"]:\n","        df[f\"{key}_truth\"] = truth_dicts.apply(lambda x: x.get(key, None))\n","        df[f\"{key}_pred\"]  = pred_dicts.apply(lambda x: x.get(key, None))\n","\n","    # ------------------------------------------------------------\n","    # Convert numeric truth/pred fields\n","    # ------------------------------------------------------------\n","    def to_float(x):\n","        try:\n","            return float(str(x).replace(\",\", \"\").strip())\n","        except:\n","            return np.nan\n","\n","    df[\"max_truth\"] = df[\"maximum_truth\"].apply(to_float)\n","    df[\"min_truth\"] = df[\"minimum_truth\"].apply(to_float)\n","    df[\"max_pred\"]  = df[\"maximum_pred\"].apply(to_float)\n","    df[\"min_pred\"]  = df[\"minimum_pred\"].apply(to_float)\n","\n","    # ------------------------------------------------------------\n","    # DOMAIN — lowercasing truth, pred unchanged\n","    # ------------------------------------------------------------\n","    df[\"domain_truth\"] = df[\"domain_truth\"].astype(str).str.lower()\n","    df[\"domain_pred\"]  = df[\"domain_pred\"].astype(str).str.lower()\n","\n","    # ------------------------------------------------------------\n","    # RANGE EXTRACTION\n","    # truth → cleaned (fix_truth=True)\n","    # pred → parsed only, NOT modified (fix_truth=False)\n","    # ------------------------------------------------------------\n","    lower_truth, upper_truth = extract_bounds(df[\"range_truth\"], fix_truth=True)\n","    lower_pred,  upper_pred  = extract_bounds(df[\"range_pred\"],  fix_truth=False)\n","\n","    df[\"lower_truth\"] = lower_truth\n","    df[\"upper_truth\"] = upper_truth\n","    df[\"lower_pred\"]  = lower_pred\n","    df[\"upper_pred\"]  = upper_pred\n","\n","    # true range size for normalization\n","    df[\"true_range_size\"] = df[\"upper_truth\"] - df[\"lower_truth\"]\n","\n","    # ------------------------------------------------------------\n","    # Filter rows valid for sMAPE without changing any logic\n","    # ------------------------------------------------------------\n","    df_valid = df[\n","        (df[\"true_range_size\"] > 0) &\n","        df[\"max_truth\"].notna() & df[\"max_pred\"].notna() &\n","        df[\"min_truth\"].notna() & df[\"min_pred\"].notna() &\n","        df[\"lower_truth\"].notna() & df[\"upper_truth\"].notna() &\n","        df[\"lower_pred\"].notna()  & df[\"upper_pred\"].notna()\n","    ].copy()\n","\n","    if len(df_valid) == 0:\n","        print(\"⚠ No valid rows for sMAPE computation!\")\n","        return\n","\n","    # ------------------------------------------------------------\n","    # ORIGINAL sMAPE LOGIC (UNMODIFIED)\n","    # ------------------------------------------------------------\n","    def sMAPE(actual, pred, denom):\n","        num = np.abs(pred - actual)\n","        return (\n","            np.mean(num / denom),\n","            np.mean((num / denom) ** 2)\n","        )\n","\n","    # ------------------------------------------------------------\n","    # TITLE METRICS\n","    # ------------------------------------------------------------\n","    titles_true = df_valid[\"title_truth\"].astype(str).tolist()\n","    titles_pred = df_valid[\"title_pred\"].astype(str).tolist()\n","\n","    n = len(df_valid)\n","    title_lev_distance = np.mean([\n","        Levenshtein.distance(titles_true[i], titles_pred[i]) for i in range(n)\n","    ])\n","    title_lev_similarity = np.mean([\n","        Levenshtein.ratio(titles_true[i], titles_pred[i]) for i in range(n)\n","    ])\n","\n","    # ------------------------------------------------------------\n","    # NUMERIC METRICS\n","    # ------------------------------------------------------------\n","    max_s, max_s_sq = sMAPE(df_valid[\"max_truth\"], df_valid[\"max_pred\"], df_valid[\"true_range_size\"])\n","    min_s, min_s_sq = sMAPE(df_valid[\"min_truth\"], df_valid[\"min_pred\"], df_valid[\"true_range_size\"])\n","    low_s, low_s_sq = sMAPE(df_valid[\"lower_truth\"], df_valid[\"lower_pred\"], df_valid[\"true_range_size\"])\n","    up_s, up_s_sq   = sMAPE(df_valid[\"upper_truth\"], df_valid[\"upper_pred\"], df_valid[\"true_range_size\"])\n","\n","    # ------------------------------------------------------------\n","    # DOMAIN F1 SCORE\n","    # ------------------------------------------------------------\n","    f1_domain = f1_score(df_valid[\"domain_truth\"], df_valid[\"domain_pred\"], average=\"weighted\")\n","\n","    # ------------------------------------------------------------\n","    # BUILD RESULTS\n","    # ------------------------------------------------------------\n","    results = {\n","        \"file_name\": model_name,\n","        \"f1_domain\": f1_domain,\n","        \"title_lev_distance\": title_lev_distance,\n","        \"title_lev_similarity\": title_lev_similarity,\n","        \"max_s_mape\": max_s,\n","        \"min_s_mape\": min_s,\n","        \"lower_s_mape\": low_s,\n","        \"upper_s_mape\": up_s,\n","        \"max_s_mape_sq\": max_s_sq,\n","        \"min_s_mape_sq\": min_s_sq,\n","        \"lower_s_mape_sq\": low_s_sq,\n","        \"upper_s_mape_sq\": up_s_sq,\n","    }\n","\n","    # ------------------------------------------------------------\n","    # SAVE RESULT\n","    # ------------------------------------------------------------\n","    result_df = pd.DataFrame([results])\n","\n","    try:\n","        previous = pd.read_csv(save_path)\n","\n","        # Remove older row with same model_name\n","        previous = previous[previous[\"file_name\"] != model_name]\n","\n","        # Append new results\n","        previous = pd.concat([previous, result_df], ignore_index=True)\n","\n","        previous.to_csv(save_path, index=False)\n","\n","    except FileNotFoundError:\n","        result_df.to_csv(save_path, index=False)\n","\n","    print(\"✅ Evaluation complete — scores saved to:\", save_path)"],"metadata":{"id":"7OC0hBX96E1p","executionInfo":{"status":"ok","timestamp":1764559933981,"user_tz":300,"elapsed":365,"user":{"displayName":"Compute DeepLearning","userId":"08902558907758790473"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["CSV_PATH = \"/content/drive/MyDrive/dl-project/results/ibm-granite/generated_output_4.csv\"\n","SAVE_PATH = \"/content/drive/MyDrive/dl-project/results/ibm-granite/generated_output_4_analysis.csv\"\n","\n","evaluate(CSV_PATH, SAVE_PATH, model_name=\"ibm-granite\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og1ppP-CxrIH","executionInfo":{"status":"ok","timestamp":1764559936517,"user_tz":300,"elapsed":307,"user":{"displayName":"Compute DeepLearning","userId":"08902558907758790473"}},"outputId":"3ee3e85d-77d5-4f48-964d-0e21ca12a3f1"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Evaluation complete — scores saved to: /content/drive/MyDrive/dl-project/results/ibm-granite/generated_output_4_analysis.csv\n"]}]},{"cell_type":"code","source":["TARGET_DIR = \"/content/drive/MyDrive/dl-project\"\n","os.makedirs(TARGET_DIR, exist_ok=True)\n","PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\")\n"],"metadata":{"id":"Cz4Jhsce4TIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XA4Jl0Xd4J08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764558633495,"user_tz":300,"elapsed":302,"user":{"displayName":"Compute DeepLearning","userId":"08902558907758790473"}},"outputId":"bf0663f5-615d-4251-f8ac-8c60359dcab0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Opening: /content/drive/MyDrive/dl-project/models/qwen2_5/qwen2_5_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/gemma3-4b/gemma3-4b_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/gemma-3-12b/gemma-3-12b_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/gemma-3-27b/gemma-3-27b_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/mistralai-3.2/mistralai-3.2_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/mistralai-3.1/mistralai-3.1_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/qwen_2b_instruct/qwen_2b_instruct_benchmark_results_join.csv\n","Opening: /content/drive/MyDrive/dl-project/models/granite_31_2b/granite_31_2b_benchmark_results_join.csv\n"]}],"source":["PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\")\n","\n","for dir_name in os.listdir(PROJECT_ROOT):\n","    dir_path = os.path.join(PROJECT_ROOT, dir_name)\n","\n","    if not os.path.isdir(dir_path):\n","        continue\n","\n","    for file_name in os.listdir(dir_path):\n","        if \"join\" in file_name and file_name.endswith(\".csv\"):\n","            file_path = os.path.join(dir_path, file_name)\n","            print(f\"Opening: {file_path}\")\n","\n","            # file_path =\n","\n","            # --- Read the original CSV ---\n","            with open(file_path, \"r\", newline=\"\") as csvfile:\n","                reader = csv.DictReader(csvfile)\n","                rows = []\n","                for row in reader:\n","                    # Remove commas before converting to float\n","                    max_inf_float = float(row[\"max_inf\"].replace(\",\", \"\")) if row[\"max_inf\"] else None\n","                    max_truth_float = float(row[\"max_truth\"].replace(\",\", \"\")) if row[\"max_truth\"] else None\n","                    min_inf_float = float(row[\"min_inf\"].replace(\",\", \"\")) if row[\"min_inf\"] else None\n","                    min_truth_float = float(row[\"min_truth\"].replace(\",\", \"\")) if row[\"min_truth\"] else None\n","\n","                    row[\"max_corr\"] = (max_inf_float == max_truth_float) if max_inf_float is not None and max_truth_float is not None else None\n","                    row[\"min_corr\"] = (min_inf_float == min_truth_float) if min_inf_float is not None and min_truth_float is not None else None\n","                    row[\"range_corr\"] = (row[\"range_inf\"] == row[\"range_truth\"])\n","                    row[\"title_corr\"] = (row[\"title_inf\"].lower() == row[\"title_truth\"].lower())\n","                    row[\"domain_corr\"] = (row[\"domain_inf\"].lower() == row[\"domain_truth\"].lower())\n","                    rows.append(row)\n","\n","                # Preserve original fieldnames, ensuring corr columns exist at the end\n","                fieldnames = reader.fieldnames.copy()\n","                new_cols = [\"max_corr\", \"min_corr\", \"range_corr\", \"title_corr\", \"domain_corr\"]\n","                for col in new_cols:\n","                    if col not in fieldnames:\n","                        fieldnames.append(col)\n","\n","            # --- Write updated CSV ---\n","            with open(file_path, \"w\", newline=\"\") as csvfile:\n","                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","                writer.writeheader()\n","                writer.writerows(rows)"]},{"cell_type":"code","source":["def parse_row(text):\n","    \"\"\"Parse a single text row like 'max: 78.0, min: 12.0, range: 0.0-90.0, title: ..., domain: ...'\"\"\"\n","    out = {}\n","\n","    # max\n","    m = re.search(r\"max:\\s*([0-9.]+)\", text)\n","    out[\"max\"] = float(m.group(1)) if m else np.nan\n","\n","    # min\n","    m = re.search(r\"min:\\s*([0-9.]+)\", text)\n","    out[\"min\"] = float(m.group(1)) if m else np.nan\n","\n","    # range\n","    m = re.search(r\"range:\\s*([0-9.]+-[0-9.]+)\", text)\n","    out[\"range\"] = m.group(1).strip() if m else None\n","\n","    # title — anything between \"title:\" and \", domain:\"\n","    m = re.search(r\"title:\\s*(.*?),\\s*domain:\", text)\n","    out[\"title\"] = m.group(1).strip() if m else \"\"\n","\n","    # domain\n","    m = re.search(r\"domain:\\s*([A-Za-z]+)\", text)\n","    out[\"domain\"] = m.group(1).strip().lower() if m else \"\"\n","\n","    return out\n"],"metadata":{"id":"bmOZ6NA35X90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(FILE_NAME):\n","\n","    os.chdir(os.path.join(PROJECT_ROOT, FILE_NAME))\n","    df = pd.read_csv(f\"{FILE_NAME}_benchmark_results_join.csv\")\n","\n","    # ------------------------\n","    # Parse truth and pred rows\n","    # ------------------------\n","    parsed_truth = df[\"truth\"].apply(parse_row)\n","    parsed_pred = df[\"pred\"].apply(parse_row)\n","\n","    for key in [\"max\", \"min\", \"range\", \"title\", \"domain\"]:\n","        df[f\"{key}_truth\"] = parsed_truth.apply(lambda d: d[key])\n","        df[f\"{key}_inf\"]   = parsed_pred.apply(lambda d: d[key])\n","\n","    # Drop incomplete rows\n","    df = df.dropna(subset=[\"max_truth\", \"min_truth\", \"range_truth\", \"title_truth\", \"domain_truth\"]).reset_index(drop=True)\n","\n","    # ------------------------\n","    # Compute metrics\n","    # ------------------------\n","    # Domain classification\n","    f1_domain = f1_score(df[\"domain_truth\"], df[\"domain_inf\"], average=\"weighted\")\n","\n","    # Title Levenshtein\n","    title_act = df[\"title_truth\"].astype(str).tolist()\n","    title_pred = df[\"title_inf\"].astype(str).tolist()\n","    n = len(df)\n","\n","    lev_distance = np.mean([Levenshtein.distance(title_act[i], title_pred[i]) for i in range(n)])\n","    lev_similarity = np.mean([Levenshtein.ratio(title_act[i], title_pred[i]) for i in range(n)])\n","\n","    # Range parsing\n","    def extract_bounds(ranges):\n","        lows, highs = [], []\n","        for s in ranges:\n","            m = re.match(r\"([0-9.]+)-([0-9.]+)\", str(s))\n","            if m:\n","                lows.append(float(m.group(1)))\n","                highs.append(float(m.group(2)))\n","            else:\n","                lows.append(np.nan)\n","                highs.append(np.nan)\n","        return np.array(lows), np.array(highs)\n","\n","    lower_pred, upper_pred = extract_bounds(df[\"range_inf\"])\n","    lower_act, upper_act   = extract_bounds(df[\"range_truth\"])\n","    range_act = upper_act - lower_act\n","\n","    # sMAPE\n","    def sMAPE(true, pred):\n","        num = np.abs(pred - true)\n","        return np.mean(num / range_act), np.mean((num / range_act) ** 2)\n","\n","    # Max/min metrics\n","    max_s_mape, max_s_mape_sq = sMAPE(df[\"max_truth\"], df[\"max_inf\"])\n","    min_s_mape, min_s_mape_sq = sMAPE(df[\"min_truth\"], df[\"min_inf\"])\n","    lower_s_mape, lower_s_mape_sq = sMAPE(lower_act, lower_pred)\n","    upper_s_mape, upper_s_mape_sq = sMAPE(upper_act, upper_pred)\n","\n","    # ------------------------\n","    # Save results into summary file\n","    # ------------------------\n","    results_dict = {\n","        \"file_name\": FILE_NAME,\n","        \"f1_domain\": f1_domain,\n","        \"title_lev_distance\": lev_distance,\n","        \"title_lev_similarity\": lev_similarity,\n","        \"max_s_mape\": max_s_mape,\n","        \"min_s_mape\": min_s_mape,\n","        \"lower_s_mape\": lower_s_mape,\n","        \"upper_s_mape\": upper_s_mape,\n","        \"max_s_mape_sq\": max_s_mape_sq,\n","        \"min_s_mape_sq\": min_s_mape_sq,\n","        \"lower_s_mape_sq\": lower_s_mape_sq,\n","        \"upper_s_mape_sq\": upper_s_mape_sq,\n","    }\n","\n","    analysis_path = os.path.join(TARGET_DIR, \"results\", \"analysis.csv\")\n","    result_df = pd.DataFrame([results_dict])\n","\n","    if os.path.exists(analysis_path):\n","        existing = pd.read_csv(analysis_path)\n","\n","        if FILE_NAME in existing[\"file_name\"].values:\n","            existing.loc[existing[\"file_name\"] == FILE_NAME] = result_df.values[0]\n","            existing.to_csv(analysis_path, index=False)\n","        else:\n","            pd.concat([existing, result_df], ignore_index=True).to_csv(analysis_path, index=False)\n","    else:\n","        result_df.to_csv(analysis_path, index=False)"],"metadata":{"id":"BDNVZNMv4Ugk"},"execution_count":null,"outputs":[]}]}