{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "teqJ9u1Eo-Ju",
        "2ugYSOxNcgtP",
        "YfEheJ9PC61_",
        "DoGeFefReUwi",
        "O5nIOVVbc9mz",
        "bmKWpo2mdBYv",
        "6X1hzMCxK22o"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt"
      ],
      "metadata": {
        "id": "teqJ9u1Eo-Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PROMPT ===\n",
        "PROMPT = f\"\"\"\n",
        "You are given an image of a graph. Your task is to analyze it and extract structured information.\n",
        "\n",
        "Return your findings as a **valid, minified JSON object** with the following fields.\n",
        "If any detail cannot be determined from the image, set its value to null (without quotes).\n",
        "\n",
        "{{\n",
        "  \"maximum\": \"The highest y-value visible on the graph.\",\n",
        "  \"minimum\": \"The lowest y-value visible on the graph.\",\n",
        "  \"range\": \"The overall span of the y-axis, written as 'min-max'.\",\n",
        "  \"title\": \"The exact title text shown on the graph, if present. If not present, write null (wthout quotes)\",\n",
        "  \"domain\": \"The subject domain of the graph. Choose ONE ONLY from the following: economics, healthcare, politics, environment, technology, entertainment, animal, linguistics, internet, miscellaneous. If none of these options are correct, output null.\"\n",
        "}}\n",
        "\n",
        "**Guidelines:**\n",
        "1. Base all answers strictly on what is visible in the graph; do not infer or invent data.\n",
        "2. Include numerical values exactly as they appear (no rounding).\n",
        "3. Maintain factual, neutral descriptions.\n",
        "4. Output only the final JSON object — no text, commentary, or markdown.\n",
        "\n",
        "Output ONLY the JSON object with string values for each aspect.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EYxEbkq5o_pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up\n"
      ],
      "metadata": {
        "id": "2ugYSOxNcgtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6K9x7fLXACv",
        "outputId": "66dbd982-77a5-45f4-dea1-6d38cf9ded74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsieRusTi_kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "41bb22d1-cc91-4135-e13b-d4ca19442015"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'roboflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2386870167.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import base64\n",
        "import csv\n",
        "from google.colab import userdata\n",
        "from io import BytesIO\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "from roboflow import Roboflow\n",
        "import shutil\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXYXgBmFjBN1",
        "outputId": "92458cf2-94c7-481d-f195-f71841abd107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "rf_key = os.environ[\"ROBOFLOW_API_KEY\"]\n",
        "VERSION = 2\n",
        "# os.environ[\"API_KEY\"] = API_KEY = userdata.get('OpenRouterAPI_GMAIL')"
      ],
      "metadata": {
        "id": "EGu2Q9S_W1Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_DIR = \"/content/drive/MyDrive/dl-project\"\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "HC-NRbJup3nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Roboflow dataset\n",
        "\n",
        "os.chdir(TARGET_DIR)\n",
        "\n",
        "rf = Roboflow(api_key=rf_key)\n",
        "project = rf.workspace(\"graph-analysis\").project(\"my-first-project-qltkc\")\n",
        "version = project.version(VERSION)\n",
        "dataset = version.download(\"jsonl\")\n",
        "\n",
        "print(\"Dataset downloaded to:\", dataset.location)\n",
        "\n",
        "train_dir = os.path.join(dataset.location, \"train\")\n",
        "\n",
        "# Load annotations from the JSONL file\n",
        "jsonl_path = os.path.join(train_dir, \"annotations.jsonl\")\n",
        "if not os.path.exists(jsonl_path):\n",
        "    raise RuntimeError(f\"Annotation file not found at: {jsonl_path}\")\n",
        "\n",
        "with open(jsonl_path, \"r\") as f:\n",
        "    ground_truth = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"\\nLoaded {len(ground_truth)} samples from {jsonl_path}\")"
      ],
      "metadata": {
        "id": "KqgySWyTB8Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vars"
      ],
      "metadata": {
        "id": "YfEheJ9PC61_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE_NAME = \"qwen2_5\"; MODEL = \"qwen/qwen2.5-vl-32b-instruct:free\"\n",
        "# FILE_NAME = \"gemma3-4b\"; MODEL = \"google/gemma-3-4b-it:free\" # 35.4M tokens, 4B params\n",
        "# FILE_NAME = \"gemma-3-12b\"; MODEL = \"google/gemma-3-12b-it:free\", # 12B params, 15.5M tokens\n",
        "# FILE_NAME = \"gemma-3-27b\"; MODEL = \"google/gemma-3-27b-it:free\", # 27B params, 2.07B tokens\n",
        "# FILE_NAME = \"mistralai-3.2\"; MODEL = \"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
        "FILE_NAME = \"mistralai-3.1\"; MODEL = \"mistralai/mistral-small-3.1-24b-instruct:free\"\n",
        "\n",
        "\n",
        "# os.environ[\"API_KEY\"] = API_KEY = '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'\n",
        "# os.environ[\"API_KEY\"] = API_KEY = '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'\n",
        "# os.environ[\"API_KEY\"] = API_KEY = \"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\" # sanjana\n",
        "# os.environ[\"API_KEY\"] = API_KEY = \"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\" # sanika\n",
        "os.environ[\"API_KEY\"] = API_KEY = \"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\" # jiya\n",
        "\n",
        "PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\", FILE_NAME)\n",
        "output_path = os.path.join(PROJECT_ROOT, f\"{FILE_NAME}_benchmark_results.json\")\n",
        "counter = 0\n",
        "max_retries=5\n",
        "base_delay=2"
      ],
      "metadata": {
        "id": "yirLNH_LC6od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper methods"
      ],
      "metadata": {
        "id": "DoGeFefReUwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## clean json file\n",
        "\n",
        "def extract_json_from_response(response_text):\n",
        "    \"\"\"\n",
        "    Extracts JSON from a Markdown code block like ```json ... ```\n",
        "    or falls back to attempting to parse raw JSON.\n",
        "    \"\"\"\n",
        "    if not response_text:\n",
        "        return None\n",
        "\n",
        "    # Try to extract the JSON block inside ```json ... ```\n",
        "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", response_text, re.DOTALL)\n",
        "    if match:\n",
        "        json_str = match.group(1)\n",
        "    else:\n",
        "        # fallback: remove triple backticks or try as-is\n",
        "        json_str = response_text.strip().strip(\"`\")\n",
        "\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Could not parse JSON from model response. Returning raw text.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "0s6tbTQecy7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(image_path, annotation_text=None):\n",
        "    \"\"\"\n",
        "    Sends an image (and optional annotation) to Qwen2.5-VL via OpenRouter.\n",
        "    \"\"\"\n",
        "    # Open the image file and encode it in base64\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": f\"{PROMPT}\"},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
        "                ]}]}\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.environ['API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\",}\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(payload)\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "GiCWfxlLc0pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking"
      ],
      "metadata": {
        "id": "O5nIOVVbc9mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "if os.path.exists(output_path):\n",
        "    with open(output_path, \"r\") as f:\n",
        "        try:\n",
        "            results = json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            results = []\n",
        "processed_images = {r[\"image_filename\"] for r in results}\n",
        "images = sorted({graph.get(\"image\") for graph in ground_truth if graph.get(\"image\")})\n",
        "\n",
        "for i, image_filename in enumerate(images):\n",
        "\n",
        "    if image_filename in processed_images:\n",
        "        print(\"PROCESSED: \", image_filename)\n",
        "        continue\n",
        "    counter += 1\n",
        "    image_path = os.path.join(train_dir, image_filename)\n",
        "    if not os.path.exists(image_path):\n",
        "        continue\n",
        "\n",
        "    model_response = query(image_path)\n",
        "\n",
        "    parsed_response = extract_json_from_response(model_response)\n",
        "    result = {\n",
        "        \"image_filename\": image_filename,\n",
        "        \"model_response\": parsed_response,\n",
        "    }\n",
        "    if not parsed_response or (isinstance(parsed_response, str) and (\"Error\" in parsed_response or \"<html\" in parsed_response.lower())):\n",
        "        continue\n",
        "    results.append(result)\n",
        "    processed_images.add(image_filename)\n",
        "\n",
        "    print(f\"{i} {image_filename}\")\n",
        "\n",
        "    # --- Checkpoint every iteration ---\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\n✅ Benchmarking complete! {len(results)} total results saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "40jw-8VXMNdw",
        "outputId": "88e512fc-a159-4bb2-a429-f85245b263c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 000001_00b319b5f0f0.rf.16503e60d7b3e2deef95fe1461d91703.jpg\n",
            "1 000004_01790997a91e.rf.d5e1f9c9738e0444fcba59bb34905a80.jpg\n",
            "2 000005_017a0940ddab.rf.e7c1b3f549deb811e842478549969c5c.jpg\n",
            "3 000009_0278b786a87e.rf.81fbfccc955f24ed7d14593981b85f57.jpg\n",
            "4 000011_02ad9cae0975.rf.04aa5d9315a1a92617f947a7369a5dcf.jpg\n",
            "5 000012_02e968ffd4c2.rf.cbb25382db5607914b351cf3fad6569d.jpg\n",
            "6 000013_039c55e5bfc4.rf.9c5c15d842f86cdbdff284482312d3bb.jpg\n",
            "7 000015_04006ea043ee.rf.c65bad82a50f1701d822319bba6bfdc5.jpg\n",
            "8 000016_0414fc638de0.rf.cbcbadea73faf9146c7f307373e978da.jpg\n",
            "Error: 429 {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"mistralai/mistral-small-3.1-24b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations\",\"provider_name\":\"Chutes\"}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"mistralai/mistral-small-3.1-24b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations\",\"provider_name\":\"Chutes\"}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "11 000025_05f70dae7c55.rf.2da603e6018477112f24a7a8c3ce6cde.jpg\n",
            "12 000026_060cb925a6d7.rf.61576d99df64253a8616a91fbb148686.jpg\n",
            "Error: 429 {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"mistralai/mistral-small-3.1-24b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations\",\"provider_name\":\"Chutes\"}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Provider returned error\",\"code\":429,\"metadata\":{\"raw\":\"mistralai/mistral-small-3.1-24b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations\",\"provider_name\":\"Chutes\"}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "15 000033_07830ddd0a42.rf.ffe0057f980c39eed18a6461b83ade44.jpg\n",
            "16 000037_07e5218adb12.rf.0ea9c4238de40150a289349e654897a6.jpg\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n",
            "Error: 429 {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day\",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"50\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1762128000000\"},\"provider_name\":null}},\"user_id\":\"user_34vsbuG9dTIoWxQHJPZ5kdohIhs\"}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4247629750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2622581343.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(image_path, annotation_text)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Open the image file and encode it in base64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mencoded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     payload = {\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Model Output and Annotations"
      ],
      "metadata": {
        "id": "bmKWpo2mdBYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\", FILE_NAME)\n",
        "\n",
        "# FILE_NAME = \"qwen2_5\"; MODEL = \"qwen/qwen2.5-vl-32b-instruct:free\"\n",
        "# FILE_NAME = \"gemma3-4b\"; MODEL = \"google/gemma-3-4b-it:free\" # 35.4M tokens, 4B params\n",
        "# FILE_NAME = \"gemma-3-12b\"; MODEL = \"google/gemma-3-12b-it:free\", # 12B params, 15.5M tokens\n",
        "# FILE_NAME = \"gemma-3-27b\"; MODEL = \"google/gemma-3-27b-it:free\", # 27B params, 2.07B tokens\n",
        "# FILE_NAME = \"mistralai-3.1\"; MODEL = \"mistralai/mistral-small-3.1-24b-instruct:free\"\n",
        "# FILE_NAME = \"mistralai-3.2\"; MODEL = \"mistralai/mistral-small-3.2-24b-instruct:free\"\n"
      ],
      "metadata": {
        "id": "H5_aUeFsm8mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## write json inference output to csv file\n",
        "\n",
        "PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\")\n",
        "\n",
        "\n",
        "def generate_csv_files(FILE_NAME):\n",
        "    ## parsing annotations jsonl file\n",
        "    os.chdir(os.path.join(PROJECT_ROOT, FILE_NAME))\n",
        "    with open(f\"{FILE_NAME}_benchmark_results.json\") as f:\n",
        "        data = json.load(f)\n",
        "    df_inf = pd.json_normalize(data)\n",
        "    if 'model_response' in df_inf.columns:\n",
        "        df_inf = df_inf.drop(columns=['model_response'])\n",
        "\n",
        "    new_column_names = ['image_filename', 'max', 'min', 'range', 'title', 'domain']\n",
        "    df_inf.columns = new_column_names\n",
        "    df_inf.to_csv(f\"{FILE_NAME}_benchmark_results.csv\", index=False)\n",
        "    jsonl_file_path = jsonl_path\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    with open(jsonl_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                json_obj = json.loads(line)\n",
        "                image_name = json_obj.get(\"image\")\n",
        "                prefix = json_obj.get(\"prefix\")\n",
        "                suffix = json_obj.get(\"suffix\")\n",
        "\n",
        "                if image_name not in data:\n",
        "                    data[image_name] = {}\n",
        "                data[image_name][prefix] = suffix\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
        "                continue\n",
        "\n",
        "    with open(\"annotations_train.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"image_filename\", \"max\", \"min\", \"range\", \"title\", \"domain\"])\n",
        "\n",
        "        for img, info in data.items():\n",
        "            writer.writerow([\n",
        "                img,\n",
        "                info.get(\"What is the maximum?\", \"\"),\n",
        "                info.get(\"What is the minimum?\", \"\"),\n",
        "                info.get(\"What is the range of the y-axis? Format as min-max (No spaces)\", \"\"),\n",
        "                info.get(\"What is the title?\", \"\"),\n",
        "                info.get(\"What is the domain?\", \"\")\n",
        "            ])\n",
        "\n",
        "    df_truth = pd.read_csv(\"annotations_train.csv\")\n",
        "\n",
        "    filename = f\"{FILE_NAME}_benchmark_results_join.csv\"\n",
        "\n",
        "    merged_df = pd.merge(df_inf, df_truth, on='image_filename', how='inner')\n",
        "    merged_df.columns = ['image_filename', 'max_inf', 'min_inf', 'range_inf', 'title_inf', 'domain_inf', 'max_truth', 'min_truth', 'range_truth', 'title_truth', 'domain_truth' ]\n",
        "    merged_df.to_csv(filename, index=False)\n",
        "\n",
        "\n",
        "    # analysis\n",
        "\n",
        "\n",
        "\n",
        "    print(\"DONE: \", filename)\n",
        "\n",
        "# generate_csv_files(\"qwen2_5\")\n",
        "# generate_csv_files(\"gemma3-4b\")\n",
        "# generate_csv_files(\"gemma-3-12b\")\n",
        "generate_csv_files(\"gemma-3-27b\")\n",
        "# generate_csv_files(\"mistralai-3.1\")\n",
        "# generate_csv_files(\"mistralai-3.2\")\n",
        "\n"
      ],
      "metadata": {
        "id": "utUytgYjcO4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000c30e5-edf9-47f5-e3f4-400e1c8128ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE:  gemma-3-27b_benchmark_results_join.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "JuY_WgKKzbev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\")\n",
        "\n",
        "for dir_name in os.listdir(PROJECT_ROOT):\n",
        "    dir_path = os.path.join(PROJECT_ROOT, dir_name)\n",
        "\n",
        "    if not os.path.isdir(dir_path):\n",
        "        continue\n",
        "\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        if \"join\" in file_name and file_name.endswith(\".csv\"):\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            print(f\"Opening: {file_path}\")\n",
        "\n",
        "            file_path =\n",
        "\n",
        "            # --- Read the original CSV ---\n",
        "            with open(file_path, \"r\", newline=\"\") as csvfile:\n",
        "                reader = csv.DictReader(csvfile)\n",
        "                rows = []\n",
        "                for row in reader:\n",
        "                    # Remove commas before converting to float\n",
        "                    max_inf_float = float(row[\"max_inf\"].replace(\",\", \"\")) if row[\"max_inf\"] else None\n",
        "                    max_truth_float = float(row[\"max_truth\"].replace(\",\", \"\")) if row[\"max_truth\"] else None\n",
        "                    min_inf_float = float(row[\"min_inf\"].replace(\",\", \"\")) if row[\"min_inf\"] else None\n",
        "                    min_truth_float = float(row[\"min_truth\"].replace(\",\", \"\")) if row[\"min_truth\"] else None\n",
        "\n",
        "                    row[\"max_corr\"] = (max_inf_float == max_truth_float) if max_inf_float is not None and max_truth_float is not None else None\n",
        "                    row[\"min_corr\"] = (min_inf_float == min_truth_float) if min_inf_float is not None and min_truth_float is not None else None\n",
        "                    row[\"range_corr\"] = (row[\"range_inf\"] == row[\"range_truth\"])\n",
        "                    row[\"title_corr\"] = (row[\"title_inf\"].lower() == row[\"title_truth\"].lower())\n",
        "                    row[\"domain_corr\"] = (row[\"domain_inf\"].lower() == row[\"domain_truth\"].lower())\n",
        "                    rows.append(row)\n",
        "\n",
        "                # Preserve original fieldnames, ensuring corr columns exist at the end\n",
        "                fieldnames = reader.fieldnames.copy()\n",
        "                new_cols = [\"max_corr\", \"min_corr\", \"range_corr\", \"title_corr\", \"domain_corr\"]\n",
        "                for col in new_cols:\n",
        "                    if col not in fieldnames:\n",
        "                        fieldnames.append(col)\n",
        "\n",
        "            # --- Write updated CSV ---\n",
        "            with open(file_path, \"w\", newline=\"\") as csvfile:\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                writer.writerows(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKByRWaFzamO",
        "outputId": "7f84634e-307c-46be-d019-db7847421e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening: /content/drive/MyDrive/dl-project/models/qwen2_5/qwen2_5_benchmark_results_join.csv\n",
            "Opening: /content/drive/MyDrive/dl-project/models/gemma3-4b/gemma3-4b_benchmark_results_join.csv\n",
            "Opening: /content/drive/MyDrive/dl-project/models/gemma-3-12b/gemma-3-12b_benchmark_results_join.csv\n",
            "Opening: /content/drive/MyDrive/dl-project/models/gemma-3-27b/gemma-3-27b_benchmark_results_join.csv\n",
            "Opening: /content/drive/MyDrive/dl-project/models/mistralai-3.2/mistralai-3.2_benchmark_results_join.csv\n",
            "Opening: /content/drive/MyDrive/dl-project/models/mistralai-3.1/mistralai-3.1_benchmark_results_join.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcolAY19vtjp",
        "outputId": "7ba0ccb0-e913-41d2-9830-a572f80bb502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting Levenshtein==0.27.3 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\n",
            "Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.3 python-Levenshtein-0.27.3 rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from google.colab import userdata\n",
        "from io import BytesIO\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "import Levenshtein\n",
        "import regex as re\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVV_WOTSop5r",
        "outputId": "13b44766-a608-4ba0-9215-ef49ecc07db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_DIR = \"/content/drive/MyDrive/dl-project\"\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "PROJECT_ROOT = os.path.join(TARGET_DIR, \"models\")\n"
      ],
      "metadata": {
        "id": "Ej6w3xuLo5_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(FILE_NAME):\n",
        "\n",
        "    os.chdir(os.path.join(PROJECT_ROOT, FILE_NAME))\n",
        "    df = pd.read_csv(f\"{FILE_NAME}_benchmark_results_join.csv\")\n",
        "\n",
        "    # remove commas and convert to floats\n",
        "    df[\"max_inf\"] = df[\"max_inf\"].str.replace(\",\", \"\").astype(float) if df[\"max_inf\"].dtype == 'object' else df[\"max_inf\"]\n",
        "    df[\"max_truth\"] = df[\"max_truth\"].str.replace(\",\", \"\").astype(float) if df[\"max_truth\"].dtype == 'object' else df[\"max_truth\"]\n",
        "    df[\"min_inf\"] = df[\"min_inf\"].str.replace(\",\", \"\").astype(float) if df[\"min_inf\"].dtype == 'object' else df[\"min_inf\"]\n",
        "    df[\"min_truth\"] = df[\"min_truth\"].str.replace(\",\", \"\").astype(float) if df[\"min_truth\"].dtype == 'object' else df[\"min_truth\"]\n",
        "\n",
        "    metrics = {\n",
        "        \"max\" : {\"y_pred\": df[\"max_inf\"], \"y_act\": df[\"max_truth\"]},\n",
        "        \"min\" : {\"y_pred\": df[\"min_inf\"], \"y_act\": df[\"min_truth\"]},\n",
        "        \"range\" : {\"y_pred\": df[\"range_inf\"], \"y_act\": df[\"range_truth\"]},\n",
        "        \"title\" : {\"y_pred\": df[\"title_inf\"], \"y_act\": df[\"title_truth\"]},\n",
        "        \"domain\": {\"y_pred\": df[\"domain_inf\"], \"y_act\": df[\"domain_truth\"]}\n",
        "    }\n",
        "    n = len(df[\"title_inf\"])\n",
        "\n",
        "    metrics\n",
        "\n",
        "    ## domain\n",
        "    f1_domain = f1_score(metrics[\"domain\"][\"y_act\"], metrics[\"domain\"][\"y_pred\"], average=\"weighted\")\n",
        "\n",
        "    # domain_s_mape = np.zeros(n)\n",
        "    # domain_s_mape[np.where(df[\"domain_corr\"] == False)] = 2 ## True = 0 False = 1\n",
        "    # domain_s_mape = np.mean(domain_s_mape) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## title\n",
        "    title_pred = metrics[\"title\"][\"y_pred\"]\n",
        "    title_act = metrics[\"title\"][\"y_act\"]\n",
        "\n",
        "    distance = sum([Levenshtein.distance(str(title_act[i]), str(title_pred[i])) for i in range(n)])/n\n",
        "    similarity = sum([Levenshtein.ratio(str(title_act[i]), str(title_pred[i])) for i in range(n)])/n\n",
        "\n",
        "\n",
        "    # title_s_mape = np.zeros(n)\n",
        "    # title = df[\"title_corr\"]\n",
        "    # title_s_mape[np.where(title == False)] = 2 ## True = 0 False = 1\n",
        "    # title_s_mape = np.mean(title_s_mape) * 100\n",
        "\n",
        "    ## range\n",
        "    def extract_bounds(ranges):\n",
        "        lowers, uppers = [], []\n",
        "        for s in ranges:\n",
        "            if not isinstance(s, str):\n",
        "                s = str(s)\n",
        "            s = s.replace(\",\", \"\")  # remove commas\n",
        "            m = re.match(r\"^\\s*([0-9.]+)\\s*-\\s*([0-9.]+)\\s*$\", s)\n",
        "            if m:\n",
        "                lowers.append(float(m.group(1)))\n",
        "                uppers.append(float(m.group(2)))\n",
        "        return lowers, uppers\n",
        "\n",
        "\n",
        "    lower_pred, upper_pred = extract_bounds(metrics[\"range\"][\"y_pred\"])\n",
        "    lower_act, upper_act = extract_bounds(metrics[\"range\"][\"y_act\"])\n",
        "    range_act = np.array(upper_act)- np.array(lower_act)\n",
        "\n",
        "\n",
        "    def sMAPE(actual, predict):\n",
        "        num = np.abs(np.array(predict) - np.array(actual))\n",
        "        s_mape = np.mean(num/range_act)\n",
        "        s_mape_sq = np.mean((num/range_act)**2)\n",
        "        return s_mape, s_mape_sq\n",
        "\n",
        "    ## max\n",
        "    max_pred = metrics[\"max\"][\"y_pred\"]\n",
        "    max_act = metrics[\"max\"][\"y_act\"]\n",
        "    max_mae = mean_absolute_error(max_act, max_pred)\n",
        "    max_s_mape, max_s_mape_sq = sMAPE(max_act, max_pred)\n",
        "\n",
        "\n",
        "    ## min\n",
        "    min_pred = metrics[\"min\"][\"y_pred\"]\n",
        "    min_act = metrics[\"min\"][\"y_act\"]\n",
        "    min_mae = mean_absolute_error(min_act, min_pred)\n",
        "    min_s_mape, min_s_mape_sq = sMAPE(min_act, min_pred)\n",
        "\n",
        "\n",
        "    lower_mae = mean_absolute_error(lower_act, lower_pred)\n",
        "    upper_mae = mean_absolute_error(upper_act, upper_pred)\n",
        "\n",
        "\n",
        "    s_mape_lower, s_mape_lower_sq = sMAPE(lower_act, lower_pred)\n",
        "    s_mape_upper, s_mape_upper_sq = sMAPE(upper_act, upper_pred)\n",
        "\n",
        "    results_dict = {\n",
        "            \"file_name\": FILE_NAME,\n",
        "            \"f1_domain\": f1_domain, ## f1 score for domain\n",
        "            \"title_lev_distance\": distance, ## calculated Levenshtein distance for title\n",
        "            \"title_lev_similarity\": similarity, ## Levenshtein similarity\n",
        "            \"max_s_mape\": max_s_mape,\n",
        "            \"min_s_mape\": min_s_mape,\n",
        "            \"lower_s_mape\": s_mape_lower,\n",
        "            \"upper_s_mape\": s_mape_upper,\n",
        "            \"max_s_mape_sq\": max_s_mape_sq,\n",
        "            \"min_s_mape_sq\": min_s_mape_sq,\n",
        "            \"lower_s_mape_sq\": s_mape_lower_sq,\n",
        "            \"upper_s_mape_sq\": s_mape_upper_sq\n",
        "\n",
        "        }\n",
        "\n",
        "    result_df = pd.DataFrame([results_dict])\n",
        "    analysis_path = os.path.join(TARGET_DIR, \"results\", \"analysis.csv\")\n",
        "\n",
        "    if os.path.exists(analysis_path):\n",
        "        existing = pd.read_csv(analysis_path)\n",
        "\n",
        "        # If the file_name already exists, replace its row\n",
        "        if \"file_name\" in existing.columns and FILE_NAME in existing[\"file_name\"].values:\n",
        "            existing.loc[existing[\"file_name\"] == FILE_NAME, :] = result_df.values[0]\n",
        "            updated = existing\n",
        "        else:\n",
        "            updated = pd.concat([existing, result_df], ignore_index=True)\n",
        "\n",
        "        updated.to_csv(analysis_path, index=False)\n",
        "    else:\n",
        "        result_df.to_csv(analysis_path, index=False)\n",
        "\n",
        "\n",
        "evaluate(\"qwen2_5\")\n",
        "evaluate(\"gemma3-4b\")\n",
        "evaluate(\"gemma-3-12b\")\n",
        "evaluate(\"gemma-3-27b\")\n",
        "evaluate(\"mistralai-3.1\")\n",
        "evaluate(\"mistralai-3.2\")"
      ],
      "metadata": {
        "id": "5XXZHilOV2Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_wa8QsQJUEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}